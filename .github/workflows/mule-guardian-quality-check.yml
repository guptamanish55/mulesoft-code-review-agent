name: Mule Guardian Code Quality Check (Reusable)

# THIS IS A REUSABLE WORKFLOW - Called from other repositories
on:
  workflow_call:
    inputs:
      # Input parameters that calling repositories can customize
      compliance_threshold:
        description: 'Minimum compliance percentage required'
        required: false
        type: number
        default: 75
      pmd_version:
        description: 'PMD version to use'
        required: false
        type: string
        default: '7.0.0'
      analysis_target:
        description: 'Directory to analyze (relative to repo root)'
        required: false
        type: string
        default: '.'
      project_name:
        description: 'Name of the project being analyzed (defaults to repository name)'
        required: false
        type: string
        default: ''  # Will be dynamically set to repository name if empty
      skip_quality_gate:
        description: 'Skip quality gate check (for debugging)'
        required: false
        type: boolean
        default: false
      require_pmd:
        description: 'Fail workflow if PMD analysis fails (prevents misleading high scores from alternative analysis)'
        required: false
        type: boolean
        default: true
    outputs:
      # Outputs that calling workflows can use
      compliance_score:
        description: 'Calculated compliance percentage'
        value: ${{ jobs.code-quality-check.outputs.compliance_score }}
      total_violations:
        description: 'Total number of violations found'
        value: ${{ jobs.code-quality-check.outputs.total_violations }}
      quality_gate_passed:
        description: 'Whether quality gate passed'
        value: ${{ jobs.code-quality-check.outputs.quality_gate_passed }}

jobs:
  code-quality-check:
    runs-on: ubuntu-latest
    
    # Set outputs for the job
    outputs:
      compliance_score: ${{ steps.mule-analysis.outputs.COMPLIANCE_SCORE }}
      total_violations: ${{ steps.mule-analysis.outputs.TOTAL_VIOLATIONS }}
      quality_gate_passed: ${{ steps.quality-gate.outputs.GATE_PASSED }}
    
    steps:
    # Step 1: Get the calling repository's code
    - name: Checkout Application Code
      uses: actions/checkout@v4
      
    # Step 2: Get Mule Guardian files from this common repository
    - name: Get Mule Guardian Core Files
      uses: actions/checkout@v4
      with:
        repository: ${{ github.repository_owner }}/mulesoft-code-review-agent
        path: mule-guardian
        ref: main
        
    # Step 3: Copy core files to working directory
    - name: Setup Mule Guardian Files
      run: |
        echo "📋 Setting up Mule Guardian files..."
        
        # Copy core files from the common repo checkout
        cp mule-guardian/mulesoft_ai_code_review_agent.py .
        cp mule-guardian/comprehensive-mulesoft-ruleset-no-debug.xml .
        cp mule-guardian/requirements.txt .
        
        echo "✅ Core files copied from common repository"
        
        # Verify files exist
        for file in mulesoft_ai_code_review_agent.py comprehensive-mulesoft-ruleset-no-debug.xml requirements.txt; do
          if [ ! -f "$file" ]; then
            echo "❌ Error: $file not found"
            exit 1
          fi
          echo "✅ Found: $file"
        done
      
    # Step 4: Setup Python
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    # Step 5: Setup Java (required for PMD)
    - name: Set up Java
      uses: actions/setup-java@v4
      with:
        distribution: 'temurin'
        java-version: '11'
        
    # Step 6: Install PMD
    - name: Install PMD
      run: |
        echo "📦 Installing PMD version ${{ inputs.pmd_version }}..."
        
        # Set PMD version with fallback to stable version
        PMD_VERSION="${{ inputs.pmd_version }}"
        FALLBACK_VERSION="6.55.0"
        
        # Force install essential tools
        sudo apt-get update -qq
        sudo apt-get install -y wget unzip bc
        
        # Use a known working PMD version and simplified installation
        echo "🔄 Installing PMD 6.55.0 (known working version)..."
        
        # Download known working PMD version
        wget "https://github.com/pmd/pmd/releases/download/pmd_releases%2F6.55.0/pmd-bin-6.55.0.zip"
        unzip pmd-bin-6.55.0.zip
        
        # Check what was actually extracted
        echo "🔍 Checking extracted PMD structure..."
        ls -la pmd-bin-6.55.0/ || echo "PMD extraction directory not found"
        
        # Install to standard location
        sudo mv pmd-bin-6.55.0 /opt/pmd
        
        # Check the actual PMD structure after moving
        echo "🔍 PMD directory structure:"
        ls -la /opt/pmd/
        ls -la /opt/pmd/bin/ 2>/dev/null || echo "No bin directory found"
        
        # Find the actual PMD executable
        PMD_EXECUTABLE=""
        if [ -f "/opt/pmd/bin/pmd" ]; then
          PMD_EXECUTABLE="/opt/pmd/bin/pmd"
        elif [ -f "/opt/pmd/bin/run.sh" ]; then
          PMD_EXECUTABLE="/opt/pmd/bin/run.sh"
        elif [ -f "/opt/pmd/pmd" ]; then
          PMD_EXECUTABLE="/opt/pmd/pmd"
        else
          echo "🔍 Searching for PMD executable..."
          PMD_EXECUTABLE=$(find /opt/pmd -name "pmd" -type f -executable 2>/dev/null | head -1)
          if [ -z "$PMD_EXECUTABLE" ]; then
            PMD_EXECUTABLE=$(find /opt/pmd -name "run.sh" -type f 2>/dev/null | head -1)
          fi
        fi
        
        if [ -n "$PMD_EXECUTABLE" ]; then
          echo "✅ Found PMD executable at: $PMD_EXECUTABLE"
          sudo chmod +x "$PMD_EXECUTABLE"
          
          # Create standard path if it doesn't exist
          if [ "$PMD_EXECUTABLE" != "/opt/pmd/bin/pmd" ]; then
            sudo mkdir -p /opt/pmd/bin
            sudo ln -sf "$PMD_EXECUTABLE" /opt/pmd/bin/pmd
            echo "🔗 Created symlink: /opt/pmd/bin/pmd -> $PMD_EXECUTABLE"
          fi
        else
          echo "❌ PMD executable not found anywhere in /opt/pmd"
          echo "🔍 Complete directory listing:"
          find /opt/pmd -type f 2>/dev/null || echo "No files found"
          exit 1
        fi
        
        # Verify Java setup
        echo "☕ Java configuration:"
        java -version
        echo "JAVA_HOME: $JAVA_HOME"
        
        # Test PMD installation immediately
        echo "🧪 Testing PMD installation..."
        if /opt/pmd/bin/pmd check --help >/dev/null 2>&1; then
          echo "✅ PMD installed and working correctly (check command)"
        elif /opt/pmd/bin/pmd --version >/dev/null 2>&1; then
          echo "✅ PMD installed and working (version command)"
        elif /opt/pmd/bin/pmd -h >/dev/null 2>&1; then
          echo "✅ PMD installed and working (help command)"
        else
          echo "❌ PMD installation test failed"
          echo "🔍 Trying to run PMD for diagnostics:"
          /opt/pmd/bin/pmd 2>&1 | head -5 || echo "PMD execution completely failed"
        fi
        
        # Create expected paths for Mule Guardian compatibility
        echo "🔗 Setting up PMD paths for Mule Guardian..."
        sudo mkdir -p /opt/homebrew/bin
        sudo ln -sf /opt/pmd/bin/pmd /opt/homebrew/bin/pmd
        
        # Add to PATH
        echo "/opt/pmd/bin" >> $GITHUB_PATH
        echo "/opt/homebrew/bin" >> $GITHUB_PATH
        export PATH="/opt/pmd/bin:/opt/homebrew/bin:$PATH"
        
        # Final verification
        echo "🔍 Final PMD installation verification:"
        ls -la /opt/pmd/bin/pmd || echo "Main PMD path missing"
        ls -la /opt/homebrew/bin/pmd || echo "Homebrew PMD path missing"
        
        echo "✅ PMD installation completed successfully"
        echo "📍 PMD available at: /opt/pmd/bin/pmd"
        echo "📍 PMD symlink at: /opt/homebrew/bin/pmd"
        
    # Step 7: Install Python Dependencies
    - name: Install Python Dependencies
      run: |
        echo "📦 Installing Python dependencies..."
        
        # Upgrade pip to latest version to better handle dependency resolution
        python -m pip install --upgrade pip
        
        # Install dependencies with better error handling
        echo "🔄 Installing from requirements.txt..."
        if pip install -r requirements.txt; then
          echo "✅ Python dependencies installed successfully"
        else
          echo "⚠️ Initial installation failed, trying with dependency resolver..."
          # Try with backtracking resolver for better conflict resolution
          pip install -r requirements.txt --use-deprecated=backtrack-on-build-failures || {
            echo "❌ Dependency installation failed"
            echo "📋 Installed packages before failure:"
            pip list
            echo "🔍 Checking for specific conflicts..."
            pip check || true
            exit 1
          }
          echo "✅ Python dependencies installed with conflict resolution"
        fi
        
        echo "📋 Final installed packages:"
        pip list
        
    # Step 8: Run Mule Guardian Analysis
    - name: Run Mule Guardian Analysis
      id: mule-analysis
      run: |
        echo "🔍 Starting Mule Guardian analysis..."
        
        # Set dynamic project name if not provided
        if [ -z "${{ inputs.project_name }}" ] || [ "${{ inputs.project_name }}" = "" ]; then
          PROJECT_NAME="${{ github.event.repository.name }}"
          echo "📍 Project: $PROJECT_NAME (auto-detected from repository)"
        else
          PROJECT_NAME="${{ inputs.project_name }}"
          echo "📍 Project: $PROJECT_NAME (user-provided)"
        fi
        
        echo "📂 Analyzing: ${{ inputs.analysis_target }}"
        echo "🏢 Repository: ${{ github.repository }}"
        echo "🌿 Branch: ${{ github.ref_name }}"
        
        # Validate analysis target
        if [ ! -d "${{ inputs.analysis_target }}" ]; then
          echo "❌ Analysis target directory not found: ${{ inputs.analysis_target }}"
          exit 1
        fi
        
        # Show what we're analyzing
        echo "📁 Contents of analysis target:"
        ls -la "${{ inputs.analysis_target }}"
        
        # Find XML files to analyze
        XML_COUNT=$(find "${{ inputs.analysis_target }}" -name "*.xml" -type f | wc -l)
        echo "📊 Found $XML_COUNT XML files to analyze"
        
        if [ $XML_COUNT -eq 0 ]; then
          echo "⚠️ No XML files found in ${{ inputs.analysis_target }}"
          echo "This might not be a MuleSoft project or files are in a different location."
        fi
        
        # Run the analysis and capture output
        echo "🔍 Starting Mule Guardian analysis..."
        python mulesoft_ai_code_review_agent.py "${{ inputs.analysis_target }}" comprehensive-mulesoft-ruleset-no-debug.xml -o quality-report.json -v 2>&1 | tee analysis_output.log
        
        # Check what type of analysis was actually used
        echo ""
        echo "🧪 ANALYSIS METHOD VERIFICATION:"
        if grep -q "SUCCESS: Using FULL PMD analysis" analysis_output.log 2>/dev/null; then
          echo "✅ CONFIRMED: Full PMD analysis with comprehensive ruleset was used"
          echo "📊 This provides the most accurate compliance score"
        elif grep -q "ALTERNATIVE analysis" analysis_output.log 2>/dev/null; then
          echo "🚨 WARNING: Alternative analysis was used instead of PMD!"
          echo "🚨 This results in HIGHER compliance scores than the UI"
          echo "🚨 The UI (28% compliance) is more accurate than this result"
          echo "🚨 PMD failed to run properly - check the logs above for Java classpath errors"
          
          # Check if we should fail when PMD doesn't work
          if [ "${{ inputs.require_pmd }}" = "true" ]; then
            echo ""
            echo "💥 FAILING WORKFLOW: require_pmd=true and PMD analysis failed"
            echo "💡 This prevents misleading high compliance scores"
            echo "💡 Fix PMD installation issues or set require_pmd=false to allow alternative analysis"
            exit 1
          fi
        else
          echo "⚠️ Could not determine which analysis method was used"
          echo "📋 Last few lines of analysis output:"
          tail -10 analysis_output.log || echo "No output log found"
        fi
        echo ""
        
        # Extract results from JSON report
        if [ -f "quality-report.json" ]; then
          echo "✅ Analysis completed successfully"
          
          # Extract compliance score
          COMPLIANCE=$(grep -o '"compliance_percentage":[0-9.]*' quality-report.json | cut -d':' -f2 | head -1)
          TOTAL_VIOLATIONS=$(grep -o '"total_violations":[0-9]*' quality-report.json | cut -d':' -f2 | head -1)
          
          # Fallback calculation if not found
          if [ -z "$COMPLIANCE" ] || [ "$COMPLIANCE" = "0" ]; then
            HIGH_COUNT=$(grep -o '"HIGH":[0-9]*' quality-report.json | cut -d':' -f2 | head -1 || echo "0")
            MEDIUM_COUNT=$(grep -o '"MEDIUM":[0-9]*' quality-report.json | cut -d':' -f2 | head -1 || echo "0")
            LOW_COUNT=$(grep -o '"LOW":[0-9]*' quality-report.json | cut -d':' -f2 | head -1 || echo "0")
            
            DEDUCTION=$((HIGH_COUNT*3 + MEDIUM_COUNT*2 + LOW_COUNT*1))
            COMPLIANCE=$((100 - DEDUCTION))
            
            # Minimum compliance
            if [ $COMPLIANCE -lt 10 ]; then
              COMPLIANCE=10
            fi
          fi
          
          echo "COMPLIANCE_SCORE=$COMPLIANCE" >> $GITHUB_OUTPUT
          echo "TOTAL_VIOLATIONS=${TOTAL_VIOLATIONS:-0}" >> $GITHUB_OUTPUT
          
          echo "🛡️ Analysis Results:"
          echo "   - Compliance Score: $COMPLIANCE%"
          echo "   - Total Violations: ${TOTAL_VIOLATIONS:-0}"
          
        else
          echo "❌ Analysis failed - no report generated"
          exit 1
        fi
        
    # Step 9: Quality Gate Check
    - name: Quality Gate Check
      id: quality-gate
      run: |
        SCORE=${{ steps.mule-analysis.outputs.COMPLIANCE_SCORE }}
        THRESHOLD=${{ inputs.compliance_threshold }}
        SKIP_GATE=${{ inputs.skip_quality_gate }}
        
        echo "📊 Quality Gate Check:"
        echo "   - Compliance Score: $SCORE%"
        echo "   - Required Threshold: $THRESHOLD%"
        echo "   - Skip Quality Gate: $SKIP_GATE"
        
        # Check if alternative analysis was used and warn
        if grep -q "ALTERNATIVE analysis" analysis_output.log 2>/dev/null; then
          echo ""
          echo "🚨 CRITICAL WARNING: Alternative analysis was used!"
          echo "🚨 This score ($SCORE%) may be MISLEADINGLY HIGH"
          echo "🚨 The UI compliance score (28%) is likely more accurate"
          echo "🚨 PMD analysis failed - please fix PMD installation issues"
          echo ""
        fi
        
        if [ "$SKIP_GATE" = "true" ]; then
          echo "⚠️ Quality gate check skipped"
          echo "GATE_PASSED=true" >> $GITHUB_OUTPUT
        elif (( $(echo "$SCORE >= $THRESHOLD" | bc -l) )); then
          echo "✅ QUALITY GATE PASSED"
          echo "GATE_PASSED=true" >> $GITHUB_OUTPUT
        else
          echo "❌ QUALITY GATE FAILED"
          echo "Project compliance ($SCORE%) is below required threshold ($THRESHOLD%)"
          echo "GATE_PASSED=false" >> $GITHUB_OUTPUT
          
          if [ "$SKIP_GATE" != "true" ]; then
            exit 1
          fi
        fi
        
    # Step 10: Generate Reports
    - name: Generate Reports
      if: always()
      run: |
        echo "📄 Generating HTML report..."
        
        # Extract values for HTML report
        COMPLIANCE_SCORE="${{ steps.mule-analysis.outputs.COMPLIANCE_SCORE }}"
        TOTAL_VIOLATIONS="${{ steps.mule-analysis.outputs.TOTAL_VIOLATIONS }}"
        PROJECT_NAME="${{ inputs.project_name }}"
        THRESHOLD="${{ inputs.compliance_threshold }}"
        
        # Generate HTML report using echo statements to avoid YAML conflicts
        echo "<!DOCTYPE html>" > quality-report.html
        echo "<html><head><title>Mule Guardian Quality Report - $PROJECT_NAME</title>" >> quality-report.html
        echo "<style>body{font-family:Arial;margin:40px;background:#f5f7fa}.header{background:#667eea;color:white;padding:20px;border-radius:8px;margin-bottom:20px}.metric{display:inline-block;background:white;margin:10px;padding:20px;border-radius:8px;min-width:120px;text-align:center;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.metric h2{margin:0;font-size:2em}.metric p{margin:10px 0 0 0;color:#666}.passed{border-left:4px solid #28a745}.failed{border-left:4px solid #dc3545}.summary{background:white;padding:20px;border-radius:8px;margin:20px 0}</style>" >> quality-report.html
        echo "</head><body>" >> quality-report.html
        echo "<div class='header'><h1>🛡️ Mule Guardian Quality Report</h1><p>$PROJECT_NAME - Code Quality Analysis Results</p></div>" >> quality-report.html
        
        # Determine status class
        if [ $COMPLIANCE_SCORE -ge $THRESHOLD ]; then
          STATUS_CLASS="passed"
          STATUS_TEXT="✅ PASSED"
        else
          STATUS_CLASS="failed" 
          STATUS_TEXT="❌ FAILED"
        fi
        
        echo "<div class='metric $STATUS_CLASS'><h2>${COMPLIANCE_SCORE}%</h2><p>Compliance Score</p><small>Threshold: ${THRESHOLD}%</small></div>" >> quality-report.html
        echo "<div class='metric'><h2>$TOTAL_VIOLATIONS</h2><p>Total Violations</p></div>" >> quality-report.html
        echo "<div class='summary'>" >> quality-report.html
        echo "<h3>Analysis Summary</h3>" >> quality-report.html
        echo "<p><strong>Project:</strong> $PROJECT_NAME</p>" >> quality-report.html
        echo "<p><strong>Analysis Target:</strong> ${{ inputs.analysis_target }}</p>" >> quality-report.html
        echo "<p><strong>Quality Gate:</strong> $STATUS_TEXT</p>" >> quality-report.html
        echo "<p><strong>Timestamp:</strong> $(date)</p>" >> quality-report.html
        echo "</div>" >> quality-report.html
        echo "<p><em>Download the JSON report for detailed violation information.</em></p>" >> quality-report.html
        echo "</body></html>" >> quality-report.html
        
        echo "✅ HTML report generated successfully"
        
    # Step 11: Upload Reports as Artifacts
    - name: Upload Quality Reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: mule-guardian-quality-report-${{ inputs.project_name }}
        path: |
          quality-report.json
          quality-report.html
        retention-days: 30
        
    # Step 12: Summary
    - name: Analysis Summary
      if: always()
      run: |
        echo "🎉 MULE GUARDIAN ANALYSIS COMPLETED!"
        echo ""
        echo "📊 Results for ${{ inputs.project_name }}:"
        echo "   - Compliance Score: ${{ steps.mule-analysis.outputs.COMPLIANCE_SCORE }}%"
        echo "   - Total Violations: ${{ steps.mule-analysis.outputs.TOTAL_VIOLATIONS }}"
        echo "   - Quality Gate: $([ "${{ steps.quality-gate.outputs.GATE_PASSED }}" = "true" ] && echo "PASSED" || echo "FAILED")"
        echo ""
        echo "📁 Reports uploaded as artifact: mule-guardian-quality-report-${{ inputs.project_name }}"
        echo "🔍 Download from Actions tab for detailed analysis"
